{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"super_convergence.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2Q1IOj4yc9lZ"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"rcKprmJOdCV1","executionInfo":{"status":"ok","timestamp":1618588417735,"user_tz":240,"elapsed":4950,"user":{"displayName":"Hung-Yang Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN4kq95njvvqCwIFd6x71htqxvxm8299D6yz00=s64","userId":"06619491291973596690"}}},"source":["import torch.nn as nn\n","import math\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import CyclicLR\n","from torchsummary import summary\n","\n","import torchvision\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","import os\n","import argparse\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","\n","\n","# Importing time\n","from time import time\n","from datetime import datetime"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CAik-3EpdP_F"},"source":["# Check GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaGRBgGGDzCi","executionInfo":{"status":"ok","timestamp":1618588421211,"user_tz":240,"elapsed":689,"user":{"displayName":"Hung-Yang Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgN4kq95njvvqCwIFd6x71htqxvxm8299D6yz00=s64","userId":"06619491291973596690"}},"outputId":"f30a0d0e-b182-4ce3-8c59-f20da59c2c04"},"source":["# Check if using GPU \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if torch.cuda.is_available():\n","  print(f\"Nvidia Cuda/GPU is available!\")\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","# Path to store results\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Nvidia Cuda/GPU is available!\n","Fri Apr 16 15:53:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    28W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JY2oTOdiwKNR"},"source":["# Load Google Drive\n"]},{"cell_type":"code","metadata":{"id":"CcYbRIqevbxw"},"source":["# make sure to change it to your own path to our project folder\n","from google.colab import drive\n","drive.mount('/content/gdrive' )\n","%cd '/content/gdrive/MyDrive/Mcgill/Winter2021/ECSE552final'\n","#%cd '/content/gdrive/MyDrive/ECSE552final'\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hdisnjoIhYXu"},"source":["# Training and testing function"]},{"cell_type":"markdown","metadata":{"id":"S9Hw2ivlhO2M"},"source":["## training and testing"]},{"cell_type":"code","metadata":{"id":"o_FfQvpLhL7w"},"source":["def train_step(train_data, model, criterion, optimizer):\n","    \"\"\"Train network.\n","\n","    Args:\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","    model.train()\n","\n","    for images, labels in train_data:\n","        images = images.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","\n","        # Add training Tensor to the model (input).\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(output.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","\n","        # Run training (backward propagation).\n","        loss.backward()\n","\n","        # Optimize weights.\n","        optimizer.step()\n","\n","        \n","    epoch_loss = total_loss / len(train_data.dataset)\n","\n","    return model, accuracy, epoch_loss\n","\n","\n","\n","def test_evaluation(validation_data, model, criterion):\n","    \"\"\"Test trained network\n","    Args:\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","    model.eval()\n","\n","    for images, labels in validation_data:\n","        images = images.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        pred = model(images)\n","        loss = criterion(pred, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(pred.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","        error = (1-predicted_ok/total_images)*100\n","\n","    epoch_loss = total_loss / len(validation_data.dataset)\n","\n","    return model, accuracy, error, epoch_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21lhPHnxhVxp"},"source":["## full training and testing function with plot"]},{"cell_type":"code","metadata":{"id":"zBMk8-nohTKb"},"source":["def training_loop(model, criterion, optimizer, scheduler, train_data, validation_data, epochs, print_every=1):\n","    \"\"\"Training loop.\n","\n","    Args:\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        epochs (int): global parameter to define epochs number\n","        print_every (int): defines how many times to print training progress\n","    \"\"\"\n","    train_losses = []\n","    valid_losses = []\n","    test_error = []\n","    testing_acc = []\n","\n","    # scheduler = CyclicLR(optimizer, base_lr = 0.1, max_lr= 0.5 , step_size_up= N_EPOCHS/2 , cycle_momentum=True, base_momentum=0.95, max_momentum=0.85)\n","\n","    # Train model\n","    for epoch in range(0, epochs):\n","\n","        print (\"epoch\", epoch)\n","        # Train_step\n","        model, training_acc, train_loss = train_step(train_data, model, criterion, optimizer)\n","        train_losses.append(train_loss)\n","\n","        # Decay learning rate if needed.\n","        scheduler.step()\n","\n","        if epoch % print_every == (print_every - 1):\n","            # Validate_step\n","            with torch.no_grad():\n","                model, accuracy, error, valid_loss = test_evaluation(validation_data, model, criterion)\n","                valid_losses.append(valid_loss)\n","                test_error.append(error)\n","                testing_acc.append(accuracy)\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Training accuracy: {training_acc:.2f}%\\t'\n","                  f'Test accuracy: {accuracy:.2f}%\\t')\n","\n","    ## Save results and plot figures\n","    np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n","    np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n","    np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n","    plot_results(train_losses, valid_losses, test_error, testing_acc)\n","\n","    return model, optimizer, (train_losses, valid_losses, test_error, testing_acc)\n","\n","\n","def plot_results(train_losses, valid_losses, test_error, testing_acc):\n","    \"\"\"Plot results.\n","    Args:\n","        train_losses: training losses as calculated in the training_loop\n","        valid_losses: validation losses as calculated in the training_loop\n","        test_error: test error as calculated in the training_loop\n","    \"\"\"\n","    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n","    plt.title('aihwkit ResNet18 with CIFAR10 dataset')\n","    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Loss [A.U.]')\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'test_losses.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_error, 'r-s')\n","    plt.title('aihwkit ResNet18 with CIFAR10 dataset')\n","    plt.legend(fig[:1], ['Test Error'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test Error [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'test_error.png'))\n","    plt.close()\n","\n","    fig = plt.plot(testing_acc, 'r-s')\n","    plt.title('aihwkit ResNet18 with CIFAR10 dataset')\n","    plt.legend(fig[:1], ['Test accuracy'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test accuracy [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'test_accuracy.png'))\n","    plt.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3gFuoWHweZF"},"source":["# Training in CIFAR 10\n","Prepare data and set hyperparamter\n","\n"]},{"cell_type":"code","metadata":{"id":"1f5gPbKL9fub"},"source":["BATCH_SIZE = 512\n","\n","# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","print (\"done!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6nY-BTC8LU4K"},"source":["## Resent 18\t\n"]},{"cell_type":"markdown","metadata":{"id":"63w2shslhuvr"},"source":["### function for creating resnet 18"]},{"cell_type":"code","metadata":{"id":"ZYuH_l2FUrTr"},"source":["class Block(nn.Module):\n","    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n","        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n","        super(Block, self).__init__()\n","        self.num_layers = num_layers\n","        if self.num_layers > 34:\n","            self.expansion = 4\n","            print (\"in\")\n","        else:\n","            self.expansion = 1\n","        \n","        # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n","\n","        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU()\n","        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n","        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","        self.identity_downsample = identity_downsample\n","        self.relu2 = nn.ReLU()\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        x = self.conv2(x)     #nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n","        x = self.bn2(x)       #nn.BatchNorm2d(out_channels)\n","        x = self.relu(x)      #nn.ReLU()\n","        x = self.conv3(x)     #nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n","        x = self.bn3(x)       #nn.BatchNorm2d(out_channels * self.expansion)\n","\n","        if self.identity_downsample is not None:\n","            identity = self.identity_downsample(identity)\n","\n","        x += identity\n","        x = self.relu2(x)\n","        return x\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, num_layers, block, image_channels, num_classes):\n","        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n","                                                     f'to be 18, 34, 50, 101, or 152 '\n","        super(ResNet, self).__init__()\n","        if num_layers < 50:\n","            self.expansion = 1\n","        else:\n","            self.expansion = 4\n","        if num_layers == 18:\n","            layers = [2, 2, 2, 2]\n","        elif num_layers == 34 or num_layers == 50:\n","            layers = [3, 4, 6, 3]\n","        elif num_layers == 101:\n","            layers = [3, 4, 23, 3]\n","        else:\n","            layers = [3, 8, 36, 3]\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        #ResNetLayers\n","        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n","        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n","        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n","        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(512 * self.expansion, num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        return x\n","\n","    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n","        layers = []\n","\n","        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n","                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n","        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n","        self.in_channels = intermediate_channels * self.expansion # 256\n","        for i in range(num_residual_blocks - 1):\n","            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n","        return nn.Sequential(*layers)\n","\n","\n","def ResNet18(img_channels=3, num_classes=1000):\n","    return ResNet(18, Block, img_channels, num_classes)\n","\n","\n","\n","model = ResNet18(img_channels=3, num_classes=10).to(DEVICE)\n","summary(model, (3, 32, 32), 512)\n","# print (model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GZS8hILh8ZP"},"source":["### Training+Testing"]},{"cell_type":"code","metadata":{"id":"gtZQmftRtJfu"},"source":["model = ResNet18(img_channels=3, num_classes=10).to(DEVICE)\n","\n","N_EPOCHS = 30\n","BATCH_SIZE = 512\n","lr = 0.1\n","SEED = 1\n","N_CLASSES = 10\n","\n","%pwd\n","%mkdir 'results'/'ResNet18 with CIFAR10 dataset'\n","\n","RESULTS = os.path.join(os.getcwd(), 'results', 'ResNet18 with CIFAR10 dataset')\n","\n","print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n","      f'Start running!')\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss()\n","\n","scheduler = CyclicLR(optimizer, base_lr = 0.1, max_lr= 0.5 , step_size_up= N_EPOCHS/2 , cycle_momentum=True, base_momentum=0.95, max_momentum=0.85)\n","# scheduler = CyclicLR(optimizer, base_lr = 0.01, max_lr= 0.5 , step_size_up= N_EPOCHS/2 , cycle_momentum=True, base_momentum=0.95, max_momentum=0.85)\n","# 22:38:28 --- Epoch: 29\tTrain loss: 0.3007\tValid loss: 0.4812\tTraining accuracy: 89.31%\tTest accuracy: 84.46%\n","\n","model, optimizer, _ = training_loop(model, criterion, optimizer, scheduler, trainloader, testloader, N_EPOCHS, print_every= 1)\n","\n","print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","          f'Complete running!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dbdAchV1Cmde"},"source":["## VGG 8"]},{"cell_type":"markdown","metadata":{"id":"LCxPqDhLFj4D"},"source":["### Training parameters"]},{"cell_type":"code","metadata":{"id":"zU8kpksUCsid"},"source":["# Training parameters\n","SEED = 1\n","N_EPOCHS = 50\n","BATCH_SIZE = 1024\n","LEARNING_RATE = 0.01\n","N_CLASSES = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsgUQUHjGN9a"},"source":["### Data Preparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DccGO4ISPeRV","executionInfo":{"status":"ok","timestamp":1618340570851,"user_tz":240,"elapsed":425,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"2d7e62b5-53cf-43c0-f3a4-e04cf56cf23b"},"source":["# make directories to store the training and validation data and results at the end\n","%pwd\n","if not os.path.exists(\"vgg8_cifar10_data\") and not os.path.exists(\"vgg8_cifar10_results_with_pytorch_layers\"):\n","  print(\"Making directories....\")\n","  %mkdir vgg8_cifar10_data\n","  %mkdir vgg8_cifar10_results_with_pytorch_layers\n","else:\n","  print(\"Directories already exists!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Directories already exists!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuxCzfqcPjbz"},"source":["# set paths for training and validation data and results\n","PATH_DATASET = \"./vgg8_cifar10_data\"\n","RESULTS = \"./vgg8_cifar10_results_with_pytorch_layers\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp6bUnSaPjj8"},"source":["# load data\n","def load_images_cifar10():\n","    \"\"\"Load images for train from torchvision datasets.\"\"\"\n","\n","    mean = torch.tensor([0.4914, 0.4822, 0.4465])\n","    std = torch.tensor([0.2023, 0.1994, 0.2010])\n","\n","    print(f'Normalization data: ({mean},{std})')\n","\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n","    train_set = datasets.CIFAR10(PATH_DATASET, download=True, train=True, transform=transform)\n","    val_set = datasets.CIFAR10(PATH_DATASET, download=True, train=False, transform=transform)\n","    train_data = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","    validation_data = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    return train_data, validation_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"stttfepoGR7F"},"source":["### Architecture"]},{"cell_type":"code","metadata":{"id":"-KXPXuWuK1MX"},"source":["# adapted from https://github.com/IBM/aihwkit/blob/master/examples/11_vgg8_training.py\n","def VGG8():\n","    \"\"\"VGG8 inspired analog model.\"\"\"\n","    model = nn.Sequential(\n","        \n","        # conv layers\n","        nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        # Linear layers\n","        nn.Flatten(),\n","        nn.Linear(in_features=8192, out_features=1024),\n","        nn.ReLU(),\n","        nn.Linear(in_features=1024, out_features=N_CLASSES),\n","        nn.LogSoftmax(dim=1)\n","    )\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgwbC2ZqJsin"},"source":["### SGD Optimizer"]},{"cell_type":"code","metadata":{"id":"IwK6vE5LK6iB"},"source":["def create_sgd_optimizer(model, learning_rate):\n","    \"\"\"Create the analog-aware optimizer.\n","    Args:\n","        model (nn.Module): model to be trained\n","        learning_rate (float): global parameter to define learning rate\n","    \"\"\"\n","    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","    # optimizer.regroup_param_groups(model)\n","\n","    return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lo5REIftJtMH"},"source":["### Training Function"]},{"cell_type":"code","metadata":{"id":"dYouGC5NK9kd"},"source":["def train(train_data, model, criterion, optimizer):\n","    \"\"\"Train network.\n","    Args:\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","    model.train()\n","    for images, labels in train_data:\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","\n","        # Add training Tensor to the model (input).\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(output.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","\n","        # Run training (backward propagation).\n","        loss.backward()\n","\n","        # Optimize weights.\n","        optimizer.step()\n","        \n","    epoch_loss = total_loss / len(train_data.dataset)\n","\n","    return model, accuracy, optimizer, epoch_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"40Z-DSBfJuDA"},"source":["### Validation Function"]},{"cell_type":"code","metadata":{"id":"QkDKVZZWK989"},"source":["def validate(validation_data, model, criterion):\n","    \"\"\"Test trained network\n","    Args:\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","\n","    model.eval()\n","\n","    for images, labels in validation_data:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        pred = model(images)\n","        loss = criterion(pred, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(pred.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","        error = (1-predicted_ok/total_images)*100\n","\n","    epoch_loss = total_loss / len(validation_data.dataset)\n","\n","    return model, epoch_loss, error, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9iMse0iDJwxq"},"source":["### Training/Validation Loop"]},{"cell_type":"code","metadata":{"id":"9rr8MDvvLHJc"},"source":["def train_val_loop_sc(model, criterion, optimizer, \n","                   train_data, validation_data, epochs, \n","                   scheduler, print_every=1):\n","    \"\"\"Training loop.\n","    Args:\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        epochs (int): global parameter to define epochs number\n","        print_every (int): defines how many times to print training progress\n","    \"\"\"\n","    train_losses = []\n","    valid_losses = []\n","    test_error = []\n","    testing_acc = []\n","\n","    # Train model\n","    for epoch in range(0, epochs):\n","        \n","        # Train_step\n","        model, training_acc, optimizer, train_loss = train(train_data, model, criterion, optimizer)\n","        train_losses.append(train_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            # Validate_step\n","            with torch.no_grad():\n","                model, valid_loss, error, accuracy = validate(\n","                    validation_data, model, criterion)\n","                valid_losses.append(valid_loss)\n","                test_error.append(error)\n","                testing_acc.append(accuracy)\n","\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Training accuracy: {training_acc:.2f}%\\t'\n","                  f'Test error: {error:.2f}%\\t'\n","                  f'Test accuracy: {accuracy:.2f}%\\t')\n","        \n","        # for cyclic learning rate training \n","        scheduler.step()\n","\n","    # Save results and plot figures\n","    # np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n","    plot_results_super_convergence(train_losses, valid_losses, test_error, testing_acc)\n","\n","    return model, optimizer, (train_losses, valid_losses, test_error)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMs-usheLVUg"},"source":["def train_val_loop_nsc(model, criterion, optimizer, \n","                   train_data, validation_data, epochs, print_every=1):\n","    \"\"\"Training loop.\n","    Args:\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        epochs (int): global parameter to define epochs number\n","        print_every (int): defines how many times to print training progress\n","    \"\"\"\n","    train_losses = []\n","    valid_losses = []\n","    test_error = []\n","    testing_acc = []\n","\n","    # Train model\n","    for epoch in range(0, epochs):\n","        \n","        # Train_step\n","        model, training_acc, optimizer, train_loss = train(train_data, model, criterion, optimizer)\n","        train_losses.append(train_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            # Validate_step\n","            with torch.no_grad():\n","                model, valid_loss, error, accuracy = validate(\n","                    validation_data, model, criterion)\n","                valid_losses.append(valid_loss)\n","                test_error.append(error)\n","                testing_acc.append(accuracy)\n","\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Training accuracy: {training_acc:.2f}%\\t'\n","                  f'Test error: {error:.2f}%\\t'\n","                  f'Test accuracy: {accuracy:.2f}%\\t')\n","\n","    # Save results and plot figures\n","    # np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n","    plot_results(train_losses, valid_losses, test_error, testing_acc)\n","\n","    return model, optimizer, (train_losses, valid_losses, test_error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyBlrqEmJxY2"},"source":["### Plot Results"]},{"cell_type":"code","metadata":{"id":"HHR8FtPcLnFf"},"source":["def plot_results_super_convergence(train_losses, valid_losses, test_error, test_acc):\n","    \"\"\"Plot results.\n","    Args:\n","        train_losses: training losses as calculated in the training_loop\n","        valid_losses: validation losses as calculated in the training_loop\n","        test_error: test error as calculated in the training_loop\n","    \"\"\"\n","    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n","    plt.title('VGG8 CIFAR-10 Super Convergence Loss')\n","    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Loss [A.U.]')\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_sc_test_losses.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_error, 'r-s')\n","    plt.title('VGG8 CIFAR-10 Super Convergence Test Error')\n","    plt.legend(fig[:1], ['Test Error'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test Error [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_sc_test_error.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_acc, 'r-s')\n","    plt.title('VGG8 CIFAR-10 Super Convergence Accuracy')\n","    plt.legend(fig[:1], ['Test accuracy'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test accuracy [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_sc_test_accuracy.png'))\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YSrPHO2Ln0Z"},"source":["def plot_results(train_losses, valid_losses, test_error, test_acc):\n","    \"\"\"Plot results.\n","    Args:\n","        train_losses: training losses as calculated in the training_loop\n","        valid_losses: validation losses as calculated in the training_loop\n","        test_error: test error as calculated in the training_loop\n","    \"\"\"\n","    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n","    plt.title('VGG8 CIFAR-10 Loss')\n","    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Loss [A.U.]')\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_test_losses.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_error, 'r-s')\n","    plt.title('VGG8 CIFAR-10 Test Error')\n","    plt.legend(fig[:1], ['Test Error'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test Error [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_test_error.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_acc, 'r-s')\n","    plt.title('VGG8 CIFAR-10 Accuracy')\n","    plt.legend(fig[:1], ['Test accuracy'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test accuracy [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_cifar10_test_accuracy.png'))\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYwkLvxxKUV_"},"source":["### Main() - Super Convergence"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7qZwUf3aNth","executionInfo":{"status":"ok","timestamp":1618340596510,"user_tz":240,"elapsed":275,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"9f633917-7d19-4294-f7b6-2ea1ef643e61"},"source":["# set seed\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7eff6452e870>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pjDvyfYiaOOE","executionInfo":{"status":"ok","timestamp":1618340600871,"user_tz":240,"elapsed":2857,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"dad8a32f-6e4d-4c15-dd7b-69d79474c4e7"},"source":["# Load datasets.\n","train_data, validation_data = load_images_cifar10()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normalization data: (tensor([0.4914, 0.4822, 0.4465]),tensor([0.2023, 0.1994, 0.2010]))\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGys_GSfaOVl","executionInfo":{"status":"ok","timestamp":1618340606090,"user_tz":240,"elapsed":4334,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"7cf3dc1c-c50a-4ccf-c1f3-67573c2bd1d6"},"source":["# Prepare the model.\n","model = VGG8()\n","model.to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU()\n","  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (7): ReLU()\n","  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU()\n","  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (16): ReLU()\n","  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (18): Flatten(start_dim=1, end_dim=-1)\n","  (19): Linear(in_features=8192, out_features=1024, bias=True)\n","  (20): ReLU()\n","  (21): Linear(in_features=1024, out_features=10, bias=True)\n","  (22): LogSoftmax(dim=1)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HFzhlIy0aOaC"},"source":["# optimizer\n","optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n","\n","# super convergence scheduler\n","scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n","                                              base_lr = 0.01, \n","                                              max_lr= 0.15, \n","                                              step_size_up= math.floor(N_EPOCHS/2), \n","                                              cycle_momentum=True, \n","                                              base_momentum=0.95, \n","                                              max_momentum=0.85)\n","# loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAzYHm5xaffe","executionInfo":{"status":"ok","timestamp":1618341506139,"user_tz":240,"elapsed":895572,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"a54c378f-7f5c-4be3-e724-787decf595c4"},"source":["print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Started Vgg8 Example')\n","\n","# training loop\n","model, optimizer, _ = train_val_loop_sc(model, criterion, optimizer, \n","                                    train_data, validation_data,\n","                                        N_EPOCHS, scheduler)\n","\n","print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Completed Vgg8 Example')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","19:03:30 --- Started Vgg8 Example\n","19:04:04 --- Epoch: 0\tTrain loss: 1.5105\tValid loss: 1.6177\tTraining accuracy: 44.92%\tTest error: 59.62%\tTest accuracy: 40.38%\t\n","19:04:40 --- Epoch: 1\tTrain loss: 1.2788\tValid loss: 1.1733\tTraining accuracy: 55.29%\tTest error: 41.97%\tTest accuracy: 58.03%\t\n","19:05:16 --- Epoch: 2\tTrain loss: 0.8797\tValid loss: 0.8934\tTraining accuracy: 68.55%\tTest error: 30.50%\tTest accuracy: 69.50%\t\n","19:05:52 --- Epoch: 3\tTrain loss: 0.6960\tValid loss: 0.9109\tTraining accuracy: 75.36%\tTest error: 29.24%\tTest accuracy: 70.76%\t\n","19:06:28 --- Epoch: 4\tTrain loss: 0.6185\tValid loss: 0.8048\tTraining accuracy: 78.39%\tTest error: 27.48%\tTest accuracy: 72.52%\t\n","19:07:03 --- Epoch: 5\tTrain loss: 0.5567\tValid loss: 1.0608\tTraining accuracy: 80.41%\tTest error: 32.44%\tTest accuracy: 67.56%\t\n","19:07:39 --- Epoch: 6\tTrain loss: 0.4940\tValid loss: 0.7027\tTraining accuracy: 82.68%\tTest error: 22.90%\tTest accuracy: 77.10%\t\n","19:08:15 --- Epoch: 7\tTrain loss: 0.4398\tValid loss: 0.5719\tTraining accuracy: 84.73%\tTest error: 18.88%\tTest accuracy: 81.12%\t\n","19:08:51 --- Epoch: 8\tTrain loss: 0.4317\tValid loss: 1.3483\tTraining accuracy: 85.04%\tTest error: 33.16%\tTest accuracy: 66.84%\t\n","19:09:27 --- Epoch: 9\tTrain loss: 0.4439\tValid loss: 0.7811\tTraining accuracy: 84.70%\tTest error: 24.08%\tTest accuracy: 75.92%\t\n","19:10:03 --- Epoch: 10\tTrain loss: 0.4228\tValid loss: 1.1068\tTraining accuracy: 85.79%\tTest error: 28.82%\tTest accuracy: 71.18%\t\n","19:10:39 --- Epoch: 11\tTrain loss: 0.4058\tValid loss: 0.7230\tTraining accuracy: 86.32%\tTest error: 21.16%\tTest accuracy: 78.84%\t\n","19:11:15 --- Epoch: 12\tTrain loss: 0.3972\tValid loss: 0.6649\tTraining accuracy: 86.58%\tTest error: 19.88%\tTest accuracy: 80.12%\t\n","19:11:50 --- Epoch: 13\tTrain loss: 0.3029\tValid loss: 0.6057\tTraining accuracy: 89.95%\tTest error: 18.23%\tTest accuracy: 81.77%\t\n","19:12:26 --- Epoch: 14\tTrain loss: 0.1748\tValid loss: 0.6379\tTraining accuracy: 94.10%\tTest error: 15.95%\tTest accuracy: 84.05%\t\n","19:13:02 --- Epoch: 15\tTrain loss: 0.0792\tValid loss: 0.6460\tTraining accuracy: 97.31%\tTest error: 14.67%\tTest accuracy: 85.33%\t\n","19:13:38 --- Epoch: 16\tTrain loss: 0.0364\tValid loss: 0.5895\tTraining accuracy: 98.78%\tTest error: 12.73%\tTest accuracy: 87.27%\t\n","19:14:14 --- Epoch: 17\tTrain loss: 0.0126\tValid loss: 0.5875\tTraining accuracy: 99.67%\tTest error: 12.11%\tTest accuracy: 87.89%\t\n","19:14:50 --- Epoch: 18\tTrain loss: 0.0036\tValid loss: 0.6047\tTraining accuracy: 99.96%\tTest error: 11.81%\tTest accuracy: 88.19%\t\n","19:15:25 --- Epoch: 19\tTrain loss: 0.0015\tValid loss: 0.6205\tTraining accuracy: 99.99%\tTest error: 11.77%\tTest accuracy: 88.23%\t\n","19:16:01 --- Epoch: 20\tTrain loss: 0.0010\tValid loss: 0.6280\tTraining accuracy: 100.00%\tTest error: 11.86%\tTest accuracy: 88.14%\t\n","19:16:37 --- Epoch: 21\tTrain loss: 0.0008\tValid loss: 0.6339\tTraining accuracy: 100.00%\tTest error: 11.76%\tTest accuracy: 88.24%\t\n","19:17:13 --- Epoch: 22\tTrain loss: 0.0008\tValid loss: 0.6401\tTraining accuracy: 100.00%\tTest error: 11.81%\tTest accuracy: 88.19%\t\n","19:17:49 --- Epoch: 23\tTrain loss: 0.0007\tValid loss: 0.6407\tTraining accuracy: 100.00%\tTest error: 11.86%\tTest accuracy: 88.14%\t\n","19:18:24 --- Epoch: 24\tTrain loss: 0.0007\tValid loss: 0.6419\tTraining accuracy: 100.00%\tTest error: 11.83%\tTest accuracy: 88.17%\t\n","19:18:25 --- Completed Vgg8 Example\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DJCwkgtaKVIN"},"source":["### Main() - Non Super Convergence"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3P-VLWzlakUr","executionInfo":{"status":"ok","timestamp":1618341538734,"user_tz":240,"elapsed":522,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"36feee5c-601b-42eb-efee-0bc6c9aada06"},"source":["# set seed\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7eff6452e870>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EVf1zOIeakir","executionInfo":{"status":"ok","timestamp":1618341542843,"user_tz":240,"elapsed":2807,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"0f2902df-29e1-40cf-d3a0-3ff50afd7218"},"source":["# Load datasets.\n","train_data, validation_data = load_images_cifar10()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normalization data: (tensor([0.4914, 0.4822, 0.4465]),tensor([0.2023, 0.1994, 0.2010]))\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EVZhd8dakln","executionInfo":{"status":"ok","timestamp":1618341544381,"user_tz":240,"elapsed":458,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"dcf891e7-75e1-4362-8616-f9f941af0c2e"},"source":["# Prepare the model.\n","model = VGG8()\n","model.to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU()\n","  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (7): ReLU()\n","  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU()\n","  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (16): ReLU()\n","  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (18): Flatten(start_dim=1, end_dim=-1)\n","  (19): Linear(in_features=8192, out_features=1024, bias=True)\n","  (20): ReLU()\n","  (21): Linear(in_features=1024, out_features=10, bias=True)\n","  (22): LogSoftmax(dim=1)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6UgDC58sakoN"},"source":["# optimizer\n","optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UTkS5G_maxCC","executionInfo":{"status":"ok","timestamp":1618343345357,"user_tz":240,"elapsed":1794372,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"c1e55ba8-134d-49c0-d6f3-c2eca1108589"},"source":["print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Started Vgg8 Example')\n","\n","# training loop\n","model, optimizer, _ = train_val_loop_nsc(model, criterion, optimizer, \n","                                    train_data, validation_data,\n","                                        N_EPOCHS)\n","\n","print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Completed Vgg8 Example')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","19:19:11 --- Started Vgg8 Example\n","19:19:47 --- Epoch: 0\tTrain loss: 1.7668\tValid loss: 1.6773\tTraining accuracy: 37.11%\tTest error: 61.06%\tTest accuracy: 38.94%\t\n","19:20:23 --- Epoch: 1\tTrain loss: 1.4309\tValid loss: 1.4739\tTraining accuracy: 48.41%\tTest error: 52.43%\tTest accuracy: 47.57%\t\n","19:20:58 --- Epoch: 2\tTrain loss: 1.3010\tValid loss: 1.3946\tTraining accuracy: 52.99%\tTest error: 50.11%\tTest accuracy: 49.89%\t\n","19:21:34 --- Epoch: 3\tTrain loss: 1.1979\tValid loss: 1.1927\tTraining accuracy: 57.25%\tTest error: 42.64%\tTest accuracy: 57.36%\t\n","19:22:10 --- Epoch: 4\tTrain loss: 1.1083\tValid loss: 1.1365\tTraining accuracy: 60.51%\tTest error: 40.91%\tTest accuracy: 59.09%\t\n","19:22:46 --- Epoch: 5\tTrain loss: 1.0547\tValid loss: 1.0651\tTraining accuracy: 62.36%\tTest error: 37.99%\tTest accuracy: 62.01%\t\n","19:23:22 --- Epoch: 6\tTrain loss: 0.9749\tValid loss: 1.1161\tTraining accuracy: 65.46%\tTest error: 40.02%\tTest accuracy: 59.98%\t\n","19:23:58 --- Epoch: 7\tTrain loss: 0.9307\tValid loss: 1.1792\tTraining accuracy: 66.81%\tTest error: 40.48%\tTest accuracy: 59.52%\t\n","19:24:33 --- Epoch: 8\tTrain loss: 0.8681\tValid loss: 0.9786\tTraining accuracy: 69.53%\tTest error: 34.25%\tTest accuracy: 65.75%\t\n","19:25:09 --- Epoch: 9\tTrain loss: 0.8293\tValid loss: 1.0450\tTraining accuracy: 70.99%\tTest error: 37.35%\tTest accuracy: 62.65%\t\n","19:25:45 --- Epoch: 10\tTrain loss: 0.7958\tValid loss: 0.8695\tTraining accuracy: 72.18%\tTest error: 31.37%\tTest accuracy: 68.63%\t\n","19:26:21 --- Epoch: 11\tTrain loss: 0.7563\tValid loss: 1.0803\tTraining accuracy: 73.61%\tTest error: 35.50%\tTest accuracy: 64.50%\t\n","19:26:57 --- Epoch: 12\tTrain loss: 0.7191\tValid loss: 0.8396\tTraining accuracy: 74.88%\tTest error: 29.48%\tTest accuracy: 70.52%\t\n","19:27:32 --- Epoch: 13\tTrain loss: 0.6935\tValid loss: 1.1554\tTraining accuracy: 75.73%\tTest error: 37.36%\tTest accuracy: 62.64%\t\n","19:28:08 --- Epoch: 14\tTrain loss: 0.6546\tValid loss: 0.9669\tTraining accuracy: 77.15%\tTest error: 33.38%\tTest accuracy: 66.62%\t\n","19:28:44 --- Epoch: 15\tTrain loss: 0.6323\tValid loss: 0.8972\tTraining accuracy: 78.16%\tTest error: 29.59%\tTest accuracy: 70.41%\t\n","19:29:20 --- Epoch: 16\tTrain loss: 0.6128\tValid loss: 0.9489\tTraining accuracy: 79.22%\tTest error: 32.30%\tTest accuracy: 67.70%\t\n","19:29:56 --- Epoch: 17\tTrain loss: 0.5938\tValid loss: 1.0777\tTraining accuracy: 79.60%\tTest error: 35.70%\tTest accuracy: 64.30%\t\n","19:30:31 --- Epoch: 18\tTrain loss: 0.5470\tValid loss: 0.9528\tTraining accuracy: 81.10%\tTest error: 32.89%\tTest accuracy: 67.11%\t\n","19:31:07 --- Epoch: 19\tTrain loss: 0.5251\tValid loss: 0.8481\tTraining accuracy: 81.88%\tTest error: 29.16%\tTest accuracy: 70.84%\t\n","19:31:43 --- Epoch: 20\tTrain loss: 0.4961\tValid loss: 0.8820\tTraining accuracy: 83.07%\tTest error: 30.80%\tTest accuracy: 69.20%\t\n","19:32:19 --- Epoch: 21\tTrain loss: 0.4857\tValid loss: 1.0219\tTraining accuracy: 83.34%\tTest error: 32.95%\tTest accuracy: 67.05%\t\n","19:32:55 --- Epoch: 22\tTrain loss: 0.4483\tValid loss: 0.7310\tTraining accuracy: 85.14%\tTest error: 25.34%\tTest accuracy: 74.66%\t\n","19:33:30 --- Epoch: 23\tTrain loss: 0.4248\tValid loss: 0.7335\tTraining accuracy: 85.62%\tTest error: 25.68%\tTest accuracy: 74.32%\t\n","19:34:06 --- Epoch: 24\tTrain loss: 0.4304\tValid loss: 0.8010\tTraining accuracy: 85.45%\tTest error: 27.96%\tTest accuracy: 72.04%\t\n","19:34:42 --- Epoch: 25\tTrain loss: 0.3840\tValid loss: 0.6866\tTraining accuracy: 87.37%\tTest error: 23.93%\tTest accuracy: 76.07%\t\n","19:35:18 --- Epoch: 26\tTrain loss: 0.3526\tValid loss: 0.7410\tTraining accuracy: 88.70%\tTest error: 24.98%\tTest accuracy: 75.02%\t\n","19:35:54 --- Epoch: 27\tTrain loss: 0.3460\tValid loss: 0.6872\tTraining accuracy: 88.64%\tTest error: 23.15%\tTest accuracy: 76.85%\t\n","19:36:30 --- Epoch: 28\tTrain loss: 0.3033\tValid loss: 0.6773\tTraining accuracy: 90.73%\tTest error: 22.88%\tTest accuracy: 77.12%\t\n","19:37:06 --- Epoch: 29\tTrain loss: 0.2922\tValid loss: 0.8060\tTraining accuracy: 90.90%\tTest error: 26.00%\tTest accuracy: 74.00%\t\n","19:37:42 --- Epoch: 30\tTrain loss: 0.2439\tValid loss: 0.7884\tTraining accuracy: 93.28%\tTest error: 25.90%\tTest accuracy: 74.10%\t\n","19:38:17 --- Epoch: 31\tTrain loss: 0.2777\tValid loss: 0.7498\tTraining accuracy: 91.47%\tTest error: 25.34%\tTest accuracy: 74.66%\t\n","19:38:53 --- Epoch: 32\tTrain loss: 0.2356\tValid loss: 0.7672\tTraining accuracy: 93.42%\tTest error: 24.39%\tTest accuracy: 75.61%\t\n","19:39:29 --- Epoch: 33\tTrain loss: 0.2213\tValid loss: 1.0953\tTraining accuracy: 93.59%\tTest error: 33.23%\tTest accuracy: 66.77%\t\n","19:40:05 --- Epoch: 34\tTrain loss: 0.1850\tValid loss: 0.8972\tTraining accuracy: 95.01%\tTest error: 26.58%\tTest accuracy: 73.42%\t\n","19:40:41 --- Epoch: 35\tTrain loss: 0.1631\tValid loss: 0.6442\tTraining accuracy: 95.93%\tTest error: 21.72%\tTest accuracy: 78.28%\t\n","19:41:17 --- Epoch: 36\tTrain loss: 0.1119\tValid loss: 0.6938\tTraining accuracy: 98.30%\tTest error: 22.56%\tTest accuracy: 77.44%\t\n","19:41:53 --- Epoch: 37\tTrain loss: 0.1583\tValid loss: 0.6434\tTraining accuracy: 96.32%\tTest error: 20.79%\tTest accuracy: 79.21%\t\n","19:42:29 --- Epoch: 38\tTrain loss: 0.0835\tValid loss: 0.6285\tTraining accuracy: 99.15%\tTest error: 20.57%\tTest accuracy: 79.43%\t\n","19:43:05 --- Epoch: 39\tTrain loss: 0.0745\tValid loss: 0.6541\tTraining accuracy: 99.37%\tTest error: 21.47%\tTest accuracy: 78.53%\t\n","19:43:41 --- Epoch: 40\tTrain loss: 0.0663\tValid loss: 0.6317\tTraining accuracy: 99.47%\tTest error: 20.30%\tTest accuracy: 79.70%\t\n","19:44:17 --- Epoch: 41\tTrain loss: 0.0566\tValid loss: 0.6852\tTraining accuracy: 99.71%\tTest error: 21.81%\tTest accuracy: 78.19%\t\n","19:44:52 --- Epoch: 42\tTrain loss: 0.0503\tValid loss: 0.6497\tTraining accuracy: 99.78%\tTest error: 20.61%\tTest accuracy: 79.39%\t\n","19:45:28 --- Epoch: 43\tTrain loss: 0.0445\tValid loss: 0.6309\tTraining accuracy: 99.86%\tTest error: 19.77%\tTest accuracy: 80.23%\t\n","19:46:04 --- Epoch: 44\tTrain loss: 0.0401\tValid loss: 0.6383\tTraining accuracy: 99.90%\tTest error: 19.79%\tTest accuracy: 80.21%\t\n","19:46:40 --- Epoch: 45\tTrain loss: 0.0362\tValid loss: 0.6720\tTraining accuracy: 99.94%\tTest error: 20.92%\tTest accuracy: 79.08%\t\n","19:47:16 --- Epoch: 46\tTrain loss: 0.0324\tValid loss: 0.6921\tTraining accuracy: 99.97%\tTest error: 21.22%\tTest accuracy: 78.78%\t\n","19:47:52 --- Epoch: 47\tTrain loss: 0.0297\tValid loss: 0.6452\tTraining accuracy: 99.97%\tTest error: 19.71%\tTest accuracy: 80.29%\t\n","19:48:28 --- Epoch: 48\tTrain loss: 0.0270\tValid loss: 0.6730\tTraining accuracy: 99.98%\tTest error: 20.16%\tTest accuracy: 79.84%\t\n","19:49:03 --- Epoch: 49\tTrain loss: 0.0248\tValid loss: 0.6573\tTraining accuracy: 99.98%\tTest error: 19.71%\tTest accuracy: 80.29%\t\n","19:49:04 --- Completed Vgg8 Example\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WH4_89dXeGLS"},"source":["# Training in SVHN"]},{"cell_type":"markdown","metadata":{"id":"pL6zRZJ3fcZj"},"source":["## VGG 8"]},{"cell_type":"markdown","metadata":{"id":"xky32ld6sTgD"},"source":["### Training Parameters"]},{"cell_type":"code","metadata":{"id":"3zSOQ9TcoYP9"},"source":["# Training parameters\n","SEED = 1\n","N_EPOCHS = 50\n","BATCH_SIZE = 1024\n","LEARNING_RATE = 0.001\n","N_CLASSES = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lQoZD7KOppB_"},"source":["### Data Preparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOQjZhjomVjo","executionInfo":{"status":"ok","timestamp":1618344075854,"user_tz":240,"elapsed":528,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"e21ed91d-9dec-4bf7-d9d5-6d7b852d85b8"},"source":["# make directories to store the training and validation data and results at the end\n","%pwd\n","if not os.path.exists(\"vgg8_svhn_data\") and not os.path.exists(\"vgg8_svhn_results_with_pytorch_layers\"):\n","  print(\"Making directories....\")\n","  %mkdir vgg8_svhn_data\n","  %mkdir vgg8_svhn_results_with_pytorch_layers\n","else:\n","  print(\"Directories already exists!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Directories already exists!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WkNQRmxWmnJi"},"source":["# set paths for training and validation data and results\n","PATH_DATASET = \"./vgg8_svhn_data\"\n","RESULTS = \"./vgg8_svhn_results_with_pytorch_layers\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AEExKGbiEBA"},"source":["# load data\n","def load_images_svhn():\n","    \"\"\"Load images for train from torchvision datasets.\"\"\"\n","\n","    mean = torch.tensor([0.4377, 0.4438, 0.4728])\n","    std = torch.tensor([0.1980, 0.2010, 0.1970])\n","\n","    print(f'Normalization data: ({mean},{std})')\n","\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n","    train_set = datasets.SVHN(PATH_DATASET, download=True, split='train', transform=transform)\n","    val_set = datasets.SVHN(PATH_DATASET, download=True, split='test', transform=transform)\n","    train_data = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","    validation_data = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    return train_data, validation_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8F5JYKFkp2AM"},"source":["### Architecture"]},{"cell_type":"code","metadata":{"id":"15837BxTp9sL"},"source":["# adapted from https://github.com/IBM/aihwkit/blob/master/examples/11_vgg8_training.py\n","def VGG8():\n","    \"\"\"VGG8 inspired analog model.\"\"\"\n","    model = nn.Sequential(\n","        \n","        # conv layers\n","        nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","\n","        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1),\n","\n","        # Linear layers\n","        nn.Flatten(),\n","        nn.Linear(in_features=8192, out_features=1024),\n","        nn.ReLU(),\n","        nn.Linear(in_features=1024, out_features=N_CLASSES),\n","        nn.LogSoftmax(dim=1)\n","    )\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6vBmE9lKsBkC"},"source":["### SGD Optimizer"]},{"cell_type":"code","metadata":{"id":"q8p1msMzs4Ks"},"source":["def create_sgd_optimizer(model, learning_rate):\n","    \"\"\"Create the analog-aware optimizer.\n","    Args:\n","        model (nn.Module): model to be trained\n","        learning_rate (float): global parameter to define learning rate\n","    \"\"\"\n","    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n","    # optimizer.regroup_param_groups(model)\n","\n","    return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dUXYVUsotOj9"},"source":["### Training Function"]},{"cell_type":"code","metadata":{"id":"OARz6kyNtdsX"},"source":["def train(train_data, model, criterion, optimizer):\n","    \"\"\"Train network.\n","    Args:\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","    model.train()\n","    for images, labels in train_data:\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","\n","        # Add training Tensor to the model (input).\n","        output = model(images)\n","        loss = criterion(output, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(output.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","\n","        # Run training (backward propagation).\n","        loss.backward()\n","\n","        # Optimize weights.\n","        optimizer.step()\n","        \n","    epoch_loss = total_loss / len(train_data.dataset)\n","\n","    return model, accuracy, optimizer, epoch_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yr7XehtltZNS"},"source":["### Validation Function"]},{"cell_type":"code","metadata":{"id":"-DoTllkst23J"},"source":["def validate(validation_data, model, criterion):\n","    \"\"\"Test trained network\n","    Args:\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","    \"\"\"\n","    total_loss = 0\n","    predicted_ok = 0\n","    total_images = 0\n","\n","    model.eval()\n","\n","    for images, labels in validation_data:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        pred = model(images)\n","        loss = criterion(pred, labels)\n","        total_loss += loss.item() * images.size(0)\n","\n","        _, predicted = torch.max(pred.data, 1)\n","        total_images += labels.size(0)\n","        predicted_ok += (predicted == labels).sum().item()\n","        accuracy = predicted_ok/total_images*100\n","        error = (1-predicted_ok/total_images)*100\n","\n","    epoch_loss = total_loss / len(validation_data.dataset)\n","\n","    return model, epoch_loss, error, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NishOgXuuK3"},"source":["### Training/Validation Loop"]},{"cell_type":"code","metadata":{"id":"mBbeIqfNu07u"},"source":["def train_val_loop_sc(model, criterion, optimizer, \n","                   train_data, validation_data, epochs, \n","                   scheduler, print_every=1):\n","    \"\"\"Training loop.\n","    Args:\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        epochs (int): global parameter to define epochs number\n","        print_every (int): defines how many times to print training progress\n","    \"\"\"\n","    train_losses = []\n","    valid_losses = []\n","    test_error = []\n","    testing_acc = []\n","\n","    # Train model\n","    for epoch in range(0, epochs):\n","        \n","        # Train_step\n","        model, training_acc, optimizer, train_loss = train(train_data, model, criterion, optimizer)\n","        train_losses.append(train_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            # Validate_step\n","            with torch.no_grad():\n","                model, valid_loss, error, accuracy = validate(\n","                    validation_data, model, criterion)\n","                valid_losses.append(valid_loss)\n","                test_error.append(error)\n","                testing_acc.append(accuracy)\n","\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Training accuracy: {training_acc:.2f}%\\t'\n","                  f'Test error: {error:.2f}%\\t'\n","                  f'Test accuracy: {accuracy:.2f}%\\t')\n","        \n","        # for cyclic learning rate training \n","        scheduler.step()\n","\n","    # Save results and plot figures\n","    # np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n","    plot_results_super_convergence(train_losses, valid_losses, test_error, testing_acc)\n","\n","    return model, optimizer, (train_losses, valid_losses, test_error)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQpWYdGA8WjW"},"source":["def train_val_loop_nsc(model, criterion, optimizer, \n","                   train_data, validation_data, epochs, print_every=1):\n","    \"\"\"Training loop.\n","    Args:\n","        model (nn.Module): Trained model to be evaluated\n","        criterion (nn.CrossEntropyLoss): criterion to compute loss\n","        optimizer (Optimizer): analog model optimizer\n","        train_data (DataLoader): Validation set to perform the evaluation\n","        validation_data (DataLoader): Validation set to perform the evaluation\n","        epochs (int): global parameter to define epochs number\n","        print_every (int): defines how many times to print training progress\n","    \"\"\"\n","    train_losses = []\n","    valid_losses = []\n","    test_error = []\n","    testing_acc = []\n","\n","    # Train model\n","    for epoch in range(0, epochs):\n","        \n","        # Train_step\n","        model, training_acc, optimizer, train_loss = train(train_data, model, criterion, optimizer)\n","        train_losses.append(train_loss)\n","\n","        if epoch % print_every == (print_every - 1):\n","            # Validate_step\n","            with torch.no_grad():\n","                model, valid_loss, error, accuracy = validate(\n","                    validation_data, model, criterion)\n","                valid_losses.append(valid_loss)\n","                test_error.append(error)\n","                testing_acc.append(accuracy)\n","\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Training accuracy: {training_acc:.2f}%\\t'\n","                  f'Test error: {error:.2f}%\\t'\n","                  f'Test accuracy: {accuracy:.2f}%\\t')\n","\n","    # Save results and plot figures\n","    # np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n","    # np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n","    plot_results(train_losses, valid_losses, test_error, testing_acc)\n","\n","    return model, optimizer, (train_losses, valid_losses, test_error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TYDCPBwvlJQ"},"source":["### Plot Results"]},{"cell_type":"code","metadata":{"id":"vU7VjU7tvrTT"},"source":["def plot_results_super_convergence(train_losses, valid_losses, test_error, test_acc):\n","    \"\"\"Plot results.\n","    Args:\n","        train_losses: training losses as calculated in the training_loop\n","        valid_losses: validation losses as calculated in the training_loop\n","        test_error: test error as calculated in the training_loop\n","    \"\"\"\n","    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n","    plt.title('VGG8 SVHN Super Convergence Loss')\n","    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Loss [A.U.]')\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_sc_test_losses.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_error, 'r-s')\n","    plt.title('VGG8 SVHN Super Convergence Test Error')\n","    plt.legend(fig[:1], ['Test Error'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test Error [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_sc_test_error.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_acc, 'r-s')\n","    plt.title('VGG8 SVHN Super Convergence Accuracy')\n","    plt.legend(fig[:1], ['Test accuracy'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test accuracy [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_sc_test_accuracy.png'))\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eVQVU8D9gpd"},"source":["def plot_results(train_losses, valid_losses, test_error, test_acc):\n","    \"\"\"Plot results.\n","    Args:\n","        train_losses: training losses as calculated in the training_loop\n","        valid_losses: validation losses as calculated in the training_loop\n","        test_error: test error as calculated in the training_loop\n","    \"\"\"\n","    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n","    plt.title('VGG8 SVHN Loss')\n","    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Loss [A.U.]')\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_nsc_test_losses.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_error, 'r-s')\n","    plt.title('VGG8 SVHN Test Error')\n","    plt.legend(fig[:1], ['Test Error'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test Error [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_nsc_test_error.png'))\n","    plt.close()\n","\n","    fig = plt.plot(test_acc, 'r-s')\n","    plt.title('VGG8 SVHN Accuracy')\n","    plt.legend(fig[:1], ['Test accuracy'])\n","    plt.xlabel('Epoch number')\n","    plt.ylabel('Test accuracy [%]')\n","    plt.ylim((0, 1e2))\n","    plt.grid(which='both', linestyle='--')\n","    plt.savefig(os.path.join(RESULTS, 'vgg8_svhn_nsc_test_accuracy.png'))\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCWEuWlkvzfc"},"source":["\n","### Main() - Super Convergence"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLGahnemamnB","executionInfo":{"status":"ok","timestamp":1618344138491,"user_tz":240,"elapsed":729,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"d4c37808-e0ce-481f-fa63-594de26d02a8"},"source":["# set seed\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7eff6452e870>"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwrLspOKajdO","executionInfo":{"status":"ok","timestamp":1618344152200,"user_tz":240,"elapsed":12630,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"d8ec92d6-0b5a-4609-b9f2-b0aa56e2a652"},"source":["# Load datasets.\n","train_data, validation_data = load_images_svhn()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normalization data: (tensor([0.4377, 0.4438, 0.4728]),tensor([0.1980, 0.2010, 0.1970]))\n","Using downloaded and verified file: ./vgg8_svhn_data/train_32x32.mat\n","Using downloaded and verified file: ./vgg8_svhn_data/test_32x32.mat\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GT4gWjvJaqhm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618344153424,"user_tz":240,"elapsed":316,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"315c63fa-323f-45b7-d8c3-f8b18c420532"},"source":["# Prepare the model.\n","model = VGG8()\n","model.to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU()\n","  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (7): ReLU()\n","  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU()\n","  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (16): ReLU()\n","  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (18): Flatten(start_dim=1, end_dim=-1)\n","  (19): Linear(in_features=8192, out_features=1024, bias=True)\n","  (20): ReLU()\n","  (21): Linear(in_features=1024, out_features=10, bias=True)\n","  (22): LogSoftmax(dim=1)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ou9TVbPkasuF"},"source":["# optimizer\n","optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n","\n","# super convergence scheduler\n","scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n","                                              base_lr = 0.001, \n","                                              max_lr= 0.1, \n","                                              step_size_up= math.floor(N_EPOCHS/2), \n","                                              cycle_momentum=True, \n","                                              base_momentum=0.95, \n","                                              max_momentum=0.8)\n","# loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPLhMpN-wMee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618345565093,"user_tz":240,"elapsed":1406205,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"b554d312-83a5-405d-a356-39f375887ee7"},"source":["print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Started Vgg8 Example')\n","\n","# training loop\n","model, optimizer, _ = train_val_loop_sc(model, criterion, optimizer, \n","                                    train_data, validation_data,\n","                                        N_EPOCHS, scheduler)\n","\n","print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Completed Vgg8 Example')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","20:02:39 --- Started Vgg8 Example\n","20:03:35 --- Epoch: 0\tTrain loss: 2.1349\tValid loss: 1.9536\tTraining accuracy: 24.58%\tTest error: 65.47%\tTest accuracy: 34.53%\t\n","20:04:31 --- Epoch: 1\tTrain loss: 0.8008\tValid loss: 0.5395\tTraining accuracy: 75.72%\tTest error: 16.31%\tTest accuracy: 83.69%\t\n","20:05:28 --- Epoch: 2\tTrain loss: 0.4029\tValid loss: 0.4098\tTraining accuracy: 87.95%\tTest error: 11.91%\tTest accuracy: 88.09%\t\n","20:06:24 --- Epoch: 3\tTrain loss: 0.2889\tValid loss: 0.3408\tTraining accuracy: 91.48%\tTest error: 10.15%\tTest accuracy: 89.85%\t\n","20:07:20 --- Epoch: 4\tTrain loss: 0.2356\tValid loss: 0.2743\tTraining accuracy: 93.05%\tTest error: 7.87%\tTest accuracy: 92.13%\t\n","20:08:17 --- Epoch: 5\tTrain loss: 0.2073\tValid loss: 0.2500\tTraining accuracy: 93.95%\tTest error: 7.14%\tTest accuracy: 92.86%\t\n","20:09:13 --- Epoch: 6\tTrain loss: 0.1794\tValid loss: 0.3523\tTraining accuracy: 94.79%\tTest error: 10.42%\tTest accuracy: 89.58%\t\n","20:10:09 --- Epoch: 7\tTrain loss: 0.1670\tValid loss: 0.2866\tTraining accuracy: 95.21%\tTest error: 7.87%\tTest accuracy: 92.13%\t\n","20:11:06 --- Epoch: 8\tTrain loss: 0.1596\tValid loss: 0.2546\tTraining accuracy: 95.38%\tTest error: 6.86%\tTest accuracy: 93.14%\t\n","20:12:02 --- Epoch: 9\tTrain loss: 0.1433\tValid loss: 0.2605\tTraining accuracy: 95.80%\tTest error: 7.41%\tTest accuracy: 92.59%\t\n","20:12:58 --- Epoch: 10\tTrain loss: 0.1461\tValid loss: 0.2996\tTraining accuracy: 95.63%\tTest error: 8.84%\tTest accuracy: 91.16%\t\n","20:13:54 --- Epoch: 11\tTrain loss: 0.1486\tValid loss: 0.2664\tTraining accuracy: 95.61%\tTest error: 7.52%\tTest accuracy: 92.48%\t\n","20:14:50 --- Epoch: 12\tTrain loss: 0.1479\tValid loss: 0.2591\tTraining accuracy: 95.61%\tTest error: 7.29%\tTest accuracy: 92.71%\t\n","20:15:46 --- Epoch: 13\tTrain loss: 0.1170\tValid loss: 0.2402\tTraining accuracy: 96.47%\tTest error: 6.15%\tTest accuracy: 93.85%\t\n","20:16:43 --- Epoch: 14\tTrain loss: 0.0656\tValid loss: 0.2219\tTraining accuracy: 98.11%\tTest error: 5.42%\tTest accuracy: 94.58%\t\n","20:17:39 --- Epoch: 15\tTrain loss: 0.0268\tValid loss: 0.2529\tTraining accuracy: 99.25%\tTest error: 5.62%\tTest accuracy: 94.38%\t\n","20:18:35 --- Epoch: 16\tTrain loss: 0.0092\tValid loss: 0.2265\tTraining accuracy: 99.78%\tTest error: 4.82%\tTest accuracy: 95.18%\t\n","20:19:31 --- Epoch: 17\tTrain loss: 0.0028\tValid loss: 0.2217\tTraining accuracy: 99.96%\tTest error: 4.68%\tTest accuracy: 95.32%\t\n","20:20:27 --- Epoch: 18\tTrain loss: 0.0013\tValid loss: 0.2283\tTraining accuracy: 99.99%\tTest error: 4.63%\tTest accuracy: 95.37%\t\n","20:21:23 --- Epoch: 19\tTrain loss: 0.0010\tValid loss: 0.2290\tTraining accuracy: 99.99%\tTest error: 4.59%\tTest accuracy: 95.41%\t\n","20:22:19 --- Epoch: 20\tTrain loss: 0.0009\tValid loss: 0.2297\tTraining accuracy: 100.00%\tTest error: 4.67%\tTest accuracy: 95.33%\t\n","20:23:16 --- Epoch: 21\tTrain loss: 0.0008\tValid loss: 0.2303\tTraining accuracy: 100.00%\tTest error: 4.66%\tTest accuracy: 95.34%\t\n","20:24:12 --- Epoch: 22\tTrain loss: 0.0008\tValid loss: 0.2299\tTraining accuracy: 100.00%\tTest error: 4.66%\tTest accuracy: 95.34%\t\n","20:25:08 --- Epoch: 23\tTrain loss: 0.0008\tValid loss: 0.2297\tTraining accuracy: 100.00%\tTest error: 4.64%\tTest accuracy: 95.36%\t\n","20:26:04 --- Epoch: 24\tTrain loss: 0.0007\tValid loss: 0.2299\tTraining accuracy: 100.00%\tTest error: 4.65%\tTest accuracy: 95.35%\t\n","20:26:05 --- Completed Vgg8 Example\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K8uwAJWm7783"},"source":["### Main() - Non Super Convergence"]},{"cell_type":"code","metadata":{"id":"bLPIt4G18lTP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618345619413,"user_tz":240,"elapsed":355,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"4ae4d93f-5173-407f-c699-be2742406d43"},"source":["# set seed\n","torch.manual_seed(SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7eff6452e870>"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"fAtJtng58oVM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618345624917,"user_tz":240,"elapsed":4201,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"69e4db62-10e6-4e73-953e-998cffa9eb17"},"source":["# Load datasets.\n","train_data, validation_data = load_images_svhn()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Normalization data: (tensor([0.4377, 0.4438, 0.4728]),tensor([0.1980, 0.2010, 0.1970]))\n","Using downloaded and verified file: ./vgg8_svhn_data/train_32x32.mat\n","Using downloaded and verified file: ./vgg8_svhn_data/test_32x32.mat\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hQJBt3Px8CrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618345624919,"user_tz":240,"elapsed":2201,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"c62ec4d7-c431-4444-eb2c-1cce5d46ebd6"},"source":["# Prepare the model.\n","model = VGG8()\n","model.to(device)\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU()\n","  (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (4): ReLU()\n","  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (7): ReLU()\n","  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU()\n","  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (16): ReLU()\n","  (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (18): Flatten(start_dim=1, end_dim=-1)\n","  (19): Linear(in_features=8192, out_features=1024, bias=True)\n","  (20): ReLU()\n","  (21): Linear(in_features=1024, out_features=10, bias=True)\n","  (22): LogSoftmax(dim=1)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XIZ_PvAE8u7W"},"source":["# optimizer\n","optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n","\n","# loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LGJM7FSO8zKZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618348497261,"user_tz":240,"elapsed":2811914,"user":{"displayName":"Jack Hu","photoUrl":"","userId":"05538669673677815084"}},"outputId":"9bc63ec7-e17c-49ef-8bcc-0eddaf100113"},"source":["print(f'\\n{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Started Vgg8 Example')\n","\n","# training loop\n","model, optimizer, _ = train_val_loop_nsc(model, criterion, optimizer, \n","                                    train_data, validation_data, N_EPOCHS)\n","\n","print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","  f'Completed Vgg8 Example')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","20:28:05 --- Started Vgg8 Example\n","20:29:01 --- Epoch: 0\tTrain loss: 2.2317\tValid loss: 2.1885\tTraining accuracy: 18.78%\tTest error: 78.92%\tTest accuracy: 21.08%\t\n","20:29:57 --- Epoch: 1\tTrain loss: 2.1679\tValid loss: 2.1285\tTraining accuracy: 21.90%\tTest error: 75.52%\tTest accuracy: 24.48%\t\n","20:30:53 --- Epoch: 2\tTrain loss: 2.1058\tValid loss: 2.0580\tTraining accuracy: 26.04%\tTest error: 70.34%\tTest accuracy: 29.66%\t\n","20:31:49 --- Epoch: 3\tTrain loss: 2.0221\tValid loss: 1.9607\tTraining accuracy: 31.82%\tTest error: 66.04%\tTest accuracy: 33.96%\t\n","20:32:45 --- Epoch: 4\tTrain loss: 1.9037\tValid loss: 1.8232\tTraining accuracy: 38.91%\tTest error: 57.73%\tTest accuracy: 42.27%\t\n","20:33:42 --- Epoch: 5\tTrain loss: 1.7494\tValid loss: 1.6552\tTraining accuracy: 46.79%\tTest error: 48.67%\tTest accuracy: 51.33%\t\n","20:34:38 --- Epoch: 6\tTrain loss: 1.5761\tValid loss: 1.4839\tTraining accuracy: 54.19%\tTest error: 40.52%\tTest accuracy: 59.48%\t\n","20:35:34 --- Epoch: 7\tTrain loss: 1.4084\tValid loss: 1.3318\tTraining accuracy: 60.61%\tTest error: 36.23%\tTest accuracy: 63.77%\t\n","20:36:30 --- Epoch: 8\tTrain loss: 1.2618\tValid loss: 1.1979\tTraining accuracy: 65.63%\tTest error: 31.51%\tTest accuracy: 68.49%\t\n","20:37:26 --- Epoch: 9\tTrain loss: 1.1431\tValid loss: 1.0899\tTraining accuracy: 69.25%\tTest error: 29.46%\tTest accuracy: 70.54%\t\n","20:38:22 --- Epoch: 10\tTrain loss: 1.0442\tValid loss: 1.0087\tTraining accuracy: 72.11%\tTest error: 26.79%\tTest accuracy: 73.21%\t\n","20:39:19 --- Epoch: 11\tTrain loss: 0.9644\tValid loss: 0.9302\tTraining accuracy: 74.33%\tTest error: 24.17%\tTest accuracy: 75.83%\t\n","20:40:15 --- Epoch: 12\tTrain loss: 0.8950\tValid loss: 0.8698\tTraining accuracy: 76.28%\tTest error: 22.80%\tTest accuracy: 77.20%\t\n","20:41:11 --- Epoch: 13\tTrain loss: 0.8405\tValid loss: 0.8461\tTraining accuracy: 77.58%\tTest error: 23.18%\tTest accuracy: 76.82%\t\n","20:42:07 --- Epoch: 14\tTrain loss: 0.7919\tValid loss: 0.7842\tTraining accuracy: 78.88%\tTest error: 21.10%\tTest accuracy: 78.90%\t\n","20:43:03 --- Epoch: 15\tTrain loss: 0.7492\tValid loss: 0.7397\tTraining accuracy: 80.00%\tTest error: 20.12%\tTest accuracy: 79.88%\t\n","20:43:59 --- Epoch: 16\tTrain loss: 0.7165\tValid loss: 0.7107\tTraining accuracy: 80.64%\tTest error: 19.21%\tTest accuracy: 80.79%\t\n","20:44:56 --- Epoch: 17\tTrain loss: 0.6833\tValid loss: 0.6830\tTraining accuracy: 81.54%\tTest error: 18.70%\tTest accuracy: 81.30%\t\n","20:45:52 --- Epoch: 18\tTrain loss: 0.6564\tValid loss: 0.6588\tTraining accuracy: 82.06%\tTest error: 18.20%\tTest accuracy: 81.80%\t\n","20:46:48 --- Epoch: 19\tTrain loss: 0.6326\tValid loss: 0.6423\tTraining accuracy: 82.69%\tTest error: 17.96%\tTest accuracy: 82.04%\t\n","20:47:44 --- Epoch: 20\tTrain loss: 0.6118\tValid loss: 0.6296\tTraining accuracy: 83.22%\tTest error: 17.75%\tTest accuracy: 82.25%\t\n","20:48:40 --- Epoch: 21\tTrain loss: 0.5904\tValid loss: 0.6035\tTraining accuracy: 83.84%\tTest error: 16.87%\tTest accuracy: 83.13%\t\n","20:49:37 --- Epoch: 22\tTrain loss: 0.5749\tValid loss: 0.5935\tTraining accuracy: 84.20%\tTest error: 16.71%\tTest accuracy: 83.29%\t\n","20:50:33 --- Epoch: 23\tTrain loss: 0.5582\tValid loss: 0.5791\tTraining accuracy: 84.60%\tTest error: 16.45%\tTest accuracy: 83.55%\t\n","20:51:29 --- Epoch: 24\tTrain loss: 0.5439\tValid loss: 0.5841\tTraining accuracy: 84.98%\tTest error: 16.79%\tTest accuracy: 83.21%\t\n","20:52:25 --- Epoch: 25\tTrain loss: 0.5306\tValid loss: 0.5596\tTraining accuracy: 85.34%\tTest error: 16.01%\tTest accuracy: 83.99%\t\n","20:53:22 --- Epoch: 26\tTrain loss: 0.5192\tValid loss: 0.5468\tTraining accuracy: 85.57%\tTest error: 15.80%\tTest accuracy: 84.20%\t\n","20:54:18 --- Epoch: 27\tTrain loss: 0.5065\tValid loss: 0.5367\tTraining accuracy: 85.90%\tTest error: 15.35%\tTest accuracy: 84.65%\t\n","20:55:14 --- Epoch: 28\tTrain loss: 0.4977\tValid loss: 0.5278\tTraining accuracy: 86.10%\tTest error: 15.03%\tTest accuracy: 84.97%\t\n","20:56:10 --- Epoch: 29\tTrain loss: 0.4869\tValid loss: 0.5268\tTraining accuracy: 86.41%\tTest error: 15.30%\tTest accuracy: 84.70%\t\n","20:57:07 --- Epoch: 30\tTrain loss: 0.4790\tValid loss: 0.5149\tTraining accuracy: 86.60%\tTest error: 14.67%\tTest accuracy: 85.33%\t\n","20:58:03 --- Epoch: 31\tTrain loss: 0.4700\tValid loss: 0.5097\tTraining accuracy: 86.87%\tTest error: 14.57%\tTest accuracy: 85.43%\t\n","20:58:59 --- Epoch: 32\tTrain loss: 0.4618\tValid loss: 0.4981\tTraining accuracy: 87.09%\tTest error: 14.27%\tTest accuracy: 85.73%\t\n","20:59:55 --- Epoch: 33\tTrain loss: 0.4546\tValid loss: 0.4928\tTraining accuracy: 87.26%\tTest error: 14.10%\tTest accuracy: 85.90%\t\n","21:00:52 --- Epoch: 34\tTrain loss: 0.4474\tValid loss: 0.4934\tTraining accuracy: 87.47%\tTest error: 14.26%\tTest accuracy: 85.74%\t\n","21:01:48 --- Epoch: 35\tTrain loss: 0.4405\tValid loss: 0.4817\tTraining accuracy: 87.64%\tTest error: 13.84%\tTest accuracy: 86.16%\t\n","21:02:44 --- Epoch: 36\tTrain loss: 0.4340\tValid loss: 0.4791\tTraining accuracy: 87.83%\tTest error: 13.85%\tTest accuracy: 86.15%\t\n","21:03:40 --- Epoch: 37\tTrain loss: 0.4283\tValid loss: 0.4759\tTraining accuracy: 87.97%\tTest error: 13.79%\tTest accuracy: 86.21%\t\n","21:04:37 --- Epoch: 38\tTrain loss: 0.4224\tValid loss: 0.4711\tTraining accuracy: 88.09%\tTest error: 13.47%\tTest accuracy: 86.53%\t\n","21:05:33 --- Epoch: 39\tTrain loss: 0.4156\tValid loss: 0.4652\tTraining accuracy: 88.38%\tTest error: 13.38%\tTest accuracy: 86.62%\t\n","21:06:29 --- Epoch: 40\tTrain loss: 0.4107\tValid loss: 0.4605\tTraining accuracy: 88.50%\tTest error: 13.31%\tTest accuracy: 86.69%\t\n","21:07:26 --- Epoch: 41\tTrain loss: 0.4067\tValid loss: 0.4566\tTraining accuracy: 88.61%\tTest error: 13.03%\tTest accuracy: 86.97%\t\n","21:08:22 --- Epoch: 42\tTrain loss: 0.4008\tValid loss: 0.4558\tTraining accuracy: 88.77%\tTest error: 13.08%\tTest accuracy: 86.92%\t\n","21:09:18 --- Epoch: 43\tTrain loss: 0.3964\tValid loss: 0.4521\tTraining accuracy: 88.90%\tTest error: 12.95%\tTest accuracy: 87.05%\t\n","21:10:15 --- Epoch: 44\tTrain loss: 0.3912\tValid loss: 0.4433\tTraining accuracy: 89.05%\tTest error: 12.83%\tTest accuracy: 87.17%\t\n","21:11:11 --- Epoch: 45\tTrain loss: 0.3861\tValid loss: 0.4434\tTraining accuracy: 89.21%\tTest error: 12.65%\tTest accuracy: 87.35%\t\n","21:12:07 --- Epoch: 46\tTrain loss: 0.3820\tValid loss: 0.4371\tTraining accuracy: 89.33%\tTest error: 12.52%\tTest accuracy: 87.48%\t\n","21:13:04 --- Epoch: 47\tTrain loss: 0.3778\tValid loss: 0.4356\tTraining accuracy: 89.40%\tTest error: 12.50%\tTest accuracy: 87.50%\t\n","21:14:00 --- Epoch: 48\tTrain loss: 0.3733\tValid loss: 0.4375\tTraining accuracy: 89.54%\tTest error: 12.58%\tTest accuracy: 87.42%\t\n","21:14:56 --- Epoch: 49\tTrain loss: 0.3692\tValid loss: 0.4345\tTraining accuracy: 89.66%\tTest error: 12.52%\tTest accuracy: 87.48%\t\n","21:14:57 --- Completed Vgg8 Example\n"],"name":"stdout"}]}]}